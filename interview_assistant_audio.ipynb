{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunafita/Interview-Assistant---Audio-Interview/blob/main/interview_assistant_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vssaTwDlHZ2B"
      },
      "source": [
        "# **üß† AI-Powered Interview Assistant with Audio (English Practice)**\n",
        "\n",
        "Welcome! This notebook helps you simulate job interviews in English using your own resume and a job description. It uses GPT-4 to generate interview questions, Text-to-Speech (TTS) to speak the questions, and Whisper (Speech-to-Text) to transcribe your audio responses. The assistant then evaluates your answers and gives feedback or follow-up questions ‚Äî just like a real interview.\n",
        "\n",
        "# üéØ Objectives\n",
        "\n",
        "* Practice speaking English in a job interview context\n",
        "* Receive realistic interview questions based on your resume and a job description\n",
        "* Respond with your voice, not just typing\n",
        "* Get feedback on your answers from AI\n",
        "* Prepare more confidently for remote or live interviews\n",
        "\n",
        "# üîß Tools Used\n",
        "\n",
        "* OpenAI GPT-4 ‚Äì for generating interview questions and feedback\n",
        "* OpenAI Whisper ‚Äì to transcribe your audio answers\n",
        "* OpenAI TTS (Text-to-Speech) ‚Äì to hear the interview questions spoken aloud\n",
        "* Python ‚Äì for combining all components\n",
        "* Google Colab ‚Äì to run it all in your browser\n",
        "\n",
        "# üìã How to Use\n",
        "\n",
        "* üìÑ Paste your resume and the job description into the notebook.\n",
        "* üß† GPT-4 will generate customized interview questions.\n",
        "* üîä The AI will speak each question aloud using Text-to-Speech.\n",
        "* üéôÔ∏è You will record or upload your spoken answer.\n",
        "* üìù The assistant will transcribe your answer using Whisper.\n",
        "* üßæ GPT-4 will evaluate and respond with feedback or a follow-up question.\n",
        "* üîÅ Repeat as many times as you'd like.\n",
        "\n",
        "# ‚ö†Ô∏è Requirements\n",
        "\n",
        "* An OpenAI API Key with access to GPT-4, Whisper, and TTS\n",
        "* A microphone or audio file to upload\n",
        "* Basic understanding of English (intermediate+ recommended)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PlDwfyA7ltC"
      },
      "source": [
        "### 1. üß∞ Install and Import Required Libraries\n",
        "\n",
        "This cell installs and imports all the necessary Python and system libraries\n",
        "used throughout the notebook, including audio processing tools, display widgets,\n",
        "and the OpenAI API client.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wg8TsfwG7fa",
        "outputId": "d33823e2-bd75-4f46-8ee5-eb630e35ee41"
      },
      "outputs": [],
      "source": [
        "# üì¶ Install required libraries (only needs to be run once)\n",
        "!pip install --quiet pydub\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install pymupdf ipywidgets\n",
        "\n",
        "# üì¶ Import required libraries\n",
        "import openai\n",
        "import os\n",
        "import IPython.display as ipd\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "# üìö Additional utilities\n",
        "import tempfile\n",
        "import base64\n",
        "from IPython.display import HTML, Audio\n",
        "from getpass import getpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hhE0ygGJTVX"
      },
      "source": [
        "### 2. üîê OpenAI API Key Setup\n",
        "\n",
        "In this step, you'll securely enter your OpenAI API key, which is required to access GPT-4, Whisper (speech-to-text), and TTS (text-to-speech).  \n",
        "The notebook will test your key by listing available models to confirm the connection is successful.\n",
        "\n",
        "üëâ You can get your API key from: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHWK8pN_I82R",
        "outputId": "140a4994-5196-47a1-a07d-b423a4062c2b"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "# üîë Securely ask for the API key\n",
        "api_key = getpass(\"üîê Enter your OpenAI API Key: \")\n",
        "\n",
        "# üéØ Initialize the OpenAI client with your key\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# ‚úÖ Test the key by listing available models\n",
        "try:\n",
        "    models = client.models.list()\n",
        "    print(\"‚úÖ API key is valid. OpenAI models retrieved successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Failed to authenticate. Please check your API key.\")\n",
        "    print(\"Error:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEczAHbR7_uW"
      },
      "source": [
        "### 3. üìÑ Resume Input Type Selection\n",
        "\n",
        "In this step, you'll choose how to provide your resume:\n",
        "- **Upload a PDF file** (recommended if your resume is already formatted)\n",
        "- **Paste the resume text manually** (if you prefer to copy and paste)\n",
        "\n",
        "After selecting an option, the notebook will display the appropriate input method in the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "035f5521f550446cb88a6969268e8f77",
            "ac204a098e994e64886a5cd10140577e",
            "331a65b6d28f4ddc89eae92dae93522a"
          ]
        },
        "id": "fbo4g679LMqz",
        "outputId": "8329d6f2-3792-431a-ab02-f3f92d8162cf"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "resume_input_type = widgets.RadioButtons(\n",
        "    options=[\"üìÑ Upload PDF file\", \"üìù Paste text manually\"],\n",
        "    value=\"üìÑ Upload PDF file\",\n",
        "    description='Resume:',\n",
        ")\n",
        "\n",
        "display(resume_input_type)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X23mTFsb8Krp"
      },
      "source": [
        "### 4. üì• Upload Resume File or Paste Text\n",
        "\n",
        "This step loads your resume based on the selected method:\n",
        "- If you chose **PDF upload**, the file will be uploaded and the text automatically extracted.\n",
        "- If you chose **manual input**, a text box will appear for you to paste your resume content.\n",
        "\n",
        "The extracted or pasted text will be stored in a variable for use in the interview simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "yr8qibAMPeF0",
        "outputId": "44d0509a-243e-438b-9664-5db6b119f439"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "if resume_input_type.value == \"üìù Paste text manually\":\n",
        "    resume_textarea = widgets.Textarea(\n",
        "        placeholder='Paste your resume here...',\n",
        "        description='Text:',\n",
        "        layout=widgets.Layout(width='100%', height='200px')\n",
        "    )\n",
        "    display(resume_textarea)\n",
        "    resume_text = resume_textarea\n",
        "else:\n",
        "    print(\"üìÑ Please upload your resume PDF file below:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Read and extract text from the uploaded PDF\n",
        "    for fname in uploaded:\n",
        "        doc = fitz.open(fname)\n",
        "        resume_text = \"\"\n",
        "        for page in doc:\n",
        "            resume_text += page.get_text()\n",
        "    print(\"‚úÖ Resume successfully loaded from PDF.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IoAlwT98dk_"
      },
      "source": [
        "### 5. üíº Paste and Confirm the Job Description\n",
        "\n",
        "In this step, paste the **job description** you want to simulate the interview for.\n",
        "\n",
        "After pasting, click the **‚úÖ Confirm Job Description** button to store the content.  \n",
        "This description will be used along with your resume to generate customized interview questions based on the target role.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "2bf3bac134b64f0b99d573d9e9f83ee2",
            "2ef66794b8e74f8bae083726e412fea3",
            "1bd820e4f3964106bac06ffc65370747",
            "ff496b1204d444698b307cbef3335433",
            "e9e0e82497b14c28bda9a45acd09692e",
            "aa0b2e99ac14423ab13dfbed2f89a98f",
            "b7c365b8c9da431f80b9da3e13d8f9f7",
            "9c80e7e0748142e29929e5b55096730d"
          ]
        },
        "id": "JqokkWDBQROa",
        "outputId": "9a3951e9-5615-417c-efd2-26baf54c2bf2"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Create TextArea for job description\n",
        "job_textarea = widgets.Textarea(\n",
        "    placeholder='Paste the job description here...',\n",
        "    description='Job:',\n",
        "    layout=widgets.Layout(width='100%', height='200px')\n",
        ")\n",
        "\n",
        "# Create Confirm button\n",
        "confirm_button = widgets.Button(\n",
        "    description='‚úÖ Confirm Job Description',\n",
        "    button_style='success',\n",
        "    tooltip='Click to store the job description',\n",
        ")\n",
        "\n",
        "# Output area to show result\n",
        "output = widgets.Output()\n",
        "\n",
        "# Handle button click\n",
        "def on_confirm_clicked(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        global job_description  # To make it accessible outside this cell\n",
        "        job_description = job_textarea.value\n",
        "        print(\"‚úÖ Job description stored successfully!\")\n",
        "\n",
        "# Attach handler\n",
        "confirm_button.on_click(on_confirm_clicked)\n",
        "\n",
        "# Display everything\n",
        "display(job_textarea, confirm_button, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SUPUpz78oBs"
      },
      "source": [
        "### 6. üß† Generate the First Interview Question with GPT-4\n",
        "\n",
        "This step uses GPT-4 to generate the **first interview question**, tailored to your resume and the job description.\n",
        "\n",
        "The assistant takes the role of a professional interviewer and focuses on assessing your fit for the role.  \n",
        "Only one question will be asked at this stage ‚Äî follow-up questions will come later based on your answers.\n",
        "\n",
        "The question will be stored and used to start the ongoing interview session.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54UpVKjrQbV-",
        "outputId": "7a856b3b-592d-4249-b15c-92064c878f5c"
      },
      "outputs": [],
      "source": [
        "# üß† Prompt to GPT-4 to act as an interviewer\n",
        "prompt = f\"\"\"\n",
        "You are a professional English-speaking job interviewer.\n",
        "\n",
        "Based on the candidate's resume and the job description below, ask the FIRST interview question only.\n",
        "\n",
        "Be realistic and focus on the candidate's fit for the job.\n",
        "\n",
        "Do not write the answer, only ask the question.\n",
        "\n",
        "Resume:\n",
        "{resume_text}\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "Now, ask your first interview question.\n",
        "\"\"\"\n",
        "\n",
        "# Create message history for ongoing conversation\n",
        "chat_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a professional English-speaking job interviewer.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# üîÅ Get the first interview question\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=chat_history,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# üó£Ô∏è Store and display the first question\n",
        "first_question = response.choices[0].message.content\n",
        "chat_history.append({\"role\": \"assistant\", \"content\": first_question})\n",
        "print(\"üó®Ô∏è Interviewer:\", first_question)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCnz1CfhSKtl"
      },
      "source": [
        "### 7. üîä Convert Interview Question to Audio (Text-to-Speech)\n",
        "\n",
        "This step uses **OpenAI‚Äôs Text-to-Speech (TTS)** engine to generate **natural-sounding audio** from the first interview question.\n",
        "\n",
        "You‚Äôll hear the question spoken aloud, simulating a real interview scenario.  \n",
        "The voice model used here is `\"alloy\"`, but you can experiment with other options like: `echo`, `fable`, `onyx`, `nova`, or `shimmer`.\n",
        "\n",
        "üëâ Make sure your speakers or headphones are on!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiNnXp-k86s9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Z_C4-GC-SSeB",
        "outputId": "a63ac0a9-4594-4de7-e10a-8737b54cbf5a"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from IPython.display import Audio\n",
        "\n",
        "# üó£Ô∏è Generate audio from the first interview question using OpenAI TTS\n",
        "speech_response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",  # Other options: 'echo', 'fable', 'onyx', 'nova', 'shimmer'\n",
        "    input=first_question\n",
        ")\n",
        "\n",
        "# üíæ Save audio to a file\n",
        "audio_path = \"first_question.mp3\"\n",
        "with open(audio_path, \"wb\") as f:\n",
        "    f.write(speech_response.content)\n",
        "\n",
        "# ‚ñ∂Ô∏è Play the audio in notebook\n",
        "display(Audio(audio_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBoeG7Wn9GF4"
      },
      "source": [
        "### 8. üéôÔ∏è Record Your Answer, Continue the Interview, and Export Transcript\n",
        "\n",
        "This cell launches the **interactive microphone interface** with three buttons:\n",
        "\n",
        "- ‚ñ∂Ô∏è **Start Recording** ‚Äì begins recording your spoken response  \n",
        "- ‚èπÔ∏è **Stop Recording** ‚Äì stops and saves the audio  \n",
        "- üõë **End Interview** ‚Äì ends the session and downloads the full transcript\n",
        "\n",
        "After each recording:\n",
        "1. Your voice is transcribed into text using **Whisper**\n",
        "2. GPT-4 reads your answer and generates a **follow-up question**\n",
        "3. The question is spoken aloud using **Text-to-Speech**\n",
        "4. The conversation is stored in `chat_history` for context\n",
        "\n",
        "At the end, a complete Markdown transcript is generated and offered as a **downloadable link**, so you can review or share your simulated interview.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "bBNRej74TQHf",
        "outputId": "87421400-6747-4001-9fe0-416376af35f2"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript, display, Audio, FileLink\n",
        "from google.colab import output\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Updated JS with blinking and state handling\n",
        "RECORD_JS = \"\"\"\n",
        "const startBtn = document.createElement(\"button\");\n",
        "const stopBtn = document.createElement(\"button\");\n",
        "const endBtn = document.createElement(\"button\");\n",
        "\n",
        "startBtn.textContent = \"‚ñ∂Ô∏è Start Recording\";\n",
        "stopBtn.textContent = \"‚èπÔ∏è Stop Recording\";\n",
        "endBtn.textContent = \"üõë End Interview\";\n",
        "\n",
        "startBtn.style = stopBtn.style = endBtn.style = \"margin: 10px; padding: 10px; font-size: 16px;\";\n",
        "startBtn.style.animation = \"\";\n",
        "\n",
        "document.body.appendChild(startBtn);\n",
        "document.body.appendChild(stopBtn);\n",
        "document.body.appendChild(endBtn);\n",
        "\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader();\n",
        "  reader.onloadend = () => resolve(reader.result);\n",
        "  reader.readAsDataURL(blob);\n",
        "});\n",
        "\n",
        "let stream;\n",
        "let recorder;\n",
        "let chunks = [];\n",
        "\n",
        "startBtn.onclick = async () => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  chunks = [];\n",
        "  recorder.ondataavailable = e => chunks.push(e.data);\n",
        "  recorder.start();\n",
        "\n",
        "  startBtn.textContent = \"üî¥ Recording...\";\n",
        "  startBtn.style.animation = \"blinker 1s linear infinite\";\n",
        "  startBtn.style.color = \"red\";\n",
        "};\n",
        "\n",
        "stopBtn.onclick = async () => {\n",
        "  recorder.stop();\n",
        "  await new Promise(resolve => recorder.onstop = resolve);\n",
        "  stream.getTracks().forEach(track => track.stop());\n",
        "\n",
        "  startBtn.textContent = \"‚ñ∂Ô∏è Start Recording\";\n",
        "  startBtn.style.animation = \"\";\n",
        "  startBtn.style.color = \"\";\n",
        "\n",
        "  let blob = new Blob(chunks);\n",
        "  let base64 = await b2text(blob);\n",
        "  google.colab.kernel.invokeFunction(\"notebook.audio_result\", [base64], {});\n",
        "};\n",
        "\n",
        "endBtn.onclick = () => {\n",
        "  google.colab.kernel.invokeFunction(\"notebook.end_interview\", [], {});\n",
        "};\n",
        "\n",
        "// CSS blinking animation\n",
        "const style = document.createElement(\"style\");\n",
        "style.textContent = `\n",
        "@keyframes blinker {\n",
        "  50% { opacity: 0.2; }\n",
        "}`;\n",
        "document.head.appendChild(style);\n",
        "\"\"\"\n",
        "\n",
        "# Callback: Process audio and continue the chat\n",
        "def handle_audio(base64_audio):\n",
        "    audio_data = base64.b64decode(base64_audio.split(',')[1])\n",
        "    audio_path = \"user_response.wav\"\n",
        "    with open(audio_path, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "    print(\"‚úÖ Audio recorded. Transcribing...\")\n",
        "\n",
        "    transcription = client.audio.transcriptions.create(\n",
        "        model=\"whisper-1\",\n",
        "        file=open(audio_path, \"rb\"),\n",
        "        response_format=\"text\"\n",
        "    )\n",
        "    user_answer = transcription.strip()\n",
        "    print(\"üìù You said:\", user_answer)\n",
        "\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_answer})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=chat_history,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    next_question = response.choices[0].message.content\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": next_question})\n",
        "    print(\"\\nüó®Ô∏è Interviewer:\", next_question)\n",
        "\n",
        "    speech = client.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"alloy\",\n",
        "        input=next_question\n",
        "    )\n",
        "    with open(\"next_question.mp3\", \"wb\") as f:\n",
        "        f.write(speech.content)\n",
        "\n",
        "    display(Audio(\"next_question.mp3\"))\n",
        "\n",
        "# Callback: Export and offer full transcript\n",
        "def end_interview():\n",
        "    print(\"üìÑ Generating transcript...\")\n",
        "\n",
        "    md_lines = [\"# üß† Interview Transcript\\n\"]\n",
        "    for entry in chat_history:\n",
        "        role = \"üë§ You\" if entry[\"role\"] == \"user\" else \"üó®Ô∏è Interviewer\"\n",
        "        md_lines.append(f\"**{role}:** {entry['content']}\\n\")\n",
        "\n",
        "    md_text = \"\\n\".join(md_lines)\n",
        "\n",
        "    # Save the file locally\n",
        "    with open(\"interview_transcript.md\", \"w\") as f:\n",
        "        f.write(md_text)\n",
        "\n",
        "    # Encode for browser-safe download link\n",
        "    b64 = base64.b64encode(md_text.encode()).decode()\n",
        "    download_link = f'<a download=\"interview_transcript.md\" href=\"data:text/markdown;base64,{b64}\" target=\"_blank\">üì• Click here to download your interview transcript</a>'\n",
        "\n",
        "    display(HTML(download_link))\n",
        "\n",
        "# Register both callbacks\n",
        "output.register_callback(\"notebook.audio_result\", handle_audio)\n",
        "output.register_callback(\"notebook.end_interview\", end_interview)\n",
        "\n",
        "# Launch interface\n",
        "display(Javascript(RECORD_JS))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOQ39zxVrc3NJMlvvoY0pge",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "035f5521f550446cb88a6969268e8f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "RadioButtonsModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "RadioButtonsModel",
            "_options_labels": [
              "üìÑ Upload PDF file",
              "üìù Paste text manually"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "RadioButtonsView",
            "description": "Resume:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_ac204a098e994e64886a5cd10140577e",
            "style": "IPY_MODEL_331a65b6d28f4ddc89eae92dae93522a"
          }
        },
        "1bd820e4f3964106bac06ffc65370747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf3bac134b64f0b99d573d9e9f83ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextareaModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Job:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2ef66794b8e74f8bae083726e412fea3",
            "placeholder": "Paste the job description here...",
            "rows": null,
            "style": "IPY_MODEL_1bd820e4f3964106bac06ffc65370747",
            "value": "Description\nHiring is broken. Most companies have no idea how to define what success looks like in a role‚Äîlet alone how to find the right person to deliver it. They rely on proxies: pedigree, resume keywords, vibes in interviews. The result? Expensive beauty pageants and costly mis-hires. It‚Äôs no wonder that the average time-to-fill a role is over 40 days, half of hires fail within 18 months, and hiring managers end up shouldering the burden of mismatched teammates. It‚Äôs a process optimized for bureaucracy, not business outcomes.\n\nWe‚Äôre building something different. Our approach starts by identifying what good looks like‚Äînot in vague competency models, but in clear, measurable outcomes. From there, we build recruiting pipelines designed like products: measurable, improvable, and ultimately scalable. When something breaks, we analyze the system, trace it to the root, and fix it. It‚Äôs not just recruiting‚Äîit‚Äôs operating system design for how great teams are built.\n\nThis is not an HR role. You‚Äôre not scheduling interviews, juggling calendars, or doing ‚Äúculture fit‚Äù theater. And it‚Äôs not a typical analyst gig either‚Äîyou‚Äôre not building dashboards for dashboard‚Äôs sake, or making decks that collect dust. In this role, you will diagnose failures in the hiring system and write deep dives that lead to real change. You‚Äôll move fast, own your insights, and be expected to persuade others to act.\n\nYou‚Äôll sit at the core of our hiring intelligence team, partnering closely with operators who are obsessed with building systems that work. You‚Äôll spend your time getting into the guts of candidate pipelines, spotting patterns others miss, and writing recommendations that actually get implemented. If you love puzzles, hate fluff, and want to put your brain to work fixing one of the most outdated systems in modern business, we want to hear from you.\n\nWhat you will be doing\nPipeline Health Analyses - Assessing the performance of hiring pipelines and identifying the root cause of any sourcing or filtering failures.\nDeep Dives - Investigating pipeline failures based on data analytics and domain-specific insights and then implementing solutions.\nStakeholder Engagement - Understanding hiring managers' business needs and keeping them aware of what Crossover can and cannot do.\nWhat you will NOT be doing\nReading and evaluating candidates' resumes or actively sourcing candidates\nManually writing job descriptions or recruitment specs (we use AI for this)\nInternal HR tasks\nKey responsibilities\nCreate and maintain scalable hiring pipelines that consistently produce high-quality hires\nCandidate requirements\nAt least 5 years of experience in a generalist business role\nProfessional experience using GenAI tools, such as ChatGPT, Claude, or Perplexity, to boost productivity at work"
          }
        },
        "2ef66794b8e74f8bae083726e412fea3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "200px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "331a65b6d28f4ddc89eae92dae93522a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c80e7e0748142e29929e5b55096730d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0b2e99ac14423ab13dfbed2f89a98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ac204a098e994e64886a5cd10140577e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7c365b8c9da431f80b9da3e13d8f9f7": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9c80e7e0748142e29929e5b55096730d",
            "msg_id": "",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "‚úÖ Job description stored successfully!\n"
                ]
              }
            ]
          }
        },
        "e9e0e82497b14c28bda9a45acd09692e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff496b1204d444698b307cbef3335433": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "‚úÖ Confirm Job Description",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e9e0e82497b14c28bda9a45acd09692e",
            "style": "IPY_MODEL_aa0b2e99ac14423ab13dfbed2f89a98f",
            "tooltip": "Click to store the job description"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
